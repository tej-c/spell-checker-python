{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing spell Checker: Use N-Gram model to get ‘N’ most likely words for a given mis-spelled word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the given word's 2-grams are:  ['sa', 'ad', 'de', 'en', 'nk', 'ka', 'ah', 'hd', 'de', 'en', 'nk', 'ki', 'im', 'me', 'en', 'ne', 'en', 'ns', 'si', 'ie', 'et', 'ts', 'se', 'em', 'mn']\n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('sadankahdenkymmenenseitsemän', 19), ('kahden', 18), ('ensimmäisen', 16), ('ensimmäisenä', 16), ('sendet', 16), ('senhor', 15), ('certainement', 14), ('denied', 14), ('deinen', 14), ('denne', 14), ('fremden', 14), ('fördenskull', 14), ('henkivartijain', 14), ('kaksikymmentä', 14), ('kuitenkin', 14), ('menkää', 14), ('seulement', 14), ('vedenpaisumuksen', 14), ('kahdeksankymmentäkuusivuotias', 14), ('kahdentenakymmenentenäseitsemäntenä', 14)]\n",
      "\n",
      "the given word's 2-grams are:  ['va', 'ar', 'rd', 'da', 'ad', 'di', 'ie', 'er', 'ra', 'am', 'ma', 'an', 'nt', 'te']\n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('madianites', 10), ('quarante', 10), ('afterward', 8), ('afterwards', 8), ('cavaram', 8), ('certamente', 8), ('daran', 8), ('disseram', 8), ('levantei', 8), ('maintenant', 8), ('mantel', 8), ('mataram', 8), ('peradventure', 8), ('servant', 8), ('verdadeiramente', 8), ('vieram', 8), ('grandissimamente', 7), ('acontecerá', 6), ('adam', 6), ('antes', 6)]\n",
      "\n",
      "the given word's 2-grams are:  ['ba', 'al', 'ls', 'se', 'em', 'me', 'er', 're', 'ed']\n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('abermals', 6), ('balsam', 6), ('certainement', 6), ('demeure', 6), ('herre', 6), ('premier', 6), ('seulement', 6), ('where', 6), ('balsamera', 5), ('balsamerade', 5), ('balsamering', 5), ('embalmed', 5), ('embalsamassem', 5), ('remembered', 5), ('als', 4), ('alsdann', 4), ('also', 4), ('beersheba', 4), ('blessed', 4), ('certamente', 4)]\n",
      "\n",
      "mrr is:  0.36\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import genesis,names,brown,webtext\n",
    "import operator\n",
    "from random import shuffle,sample\n",
    "from decimal import Decimal\n",
    "#nltk.download('webtext')\n",
    "wt = genesis.words()\n",
    "data = nltk.FreqDist(sorted(wt))\n",
    "corpus=[m.lower() for m, n in data.items()]\n",
    "#corpus=sample(corpus,len(corpus))\n",
    "#wor=[wor.lower() for wor in input(\"\\nenter some mis-spelt words: \").split(',')]\n",
    "#ogword=[ogword.lower() for ogword in input(\"\\nwhat do you think the og words are: \").split(',')]\n",
    "#n=[int(n)for n in input(\"\\nenter what kind of gramming scheme (integer) : \").split(',')]\n",
    "def spell(wor,ogword,n):\n",
    "    mrr=0\n",
    "    for i in range(len(n)):\n",
    "        lis=[]\n",
    "        while len(wor[i])>n[i]-1:\n",
    "            lis.append(wor[i][:n[i]])\n",
    "            wor[i]=wor[i][1:]\n",
    "        print(\"\\nthe given word's {}-grams are: \".format(n[i]),lis)\n",
    "        wordsfreq={}\n",
    "        for word in corpus:\n",
    "            if word not in wordsfreq:\n",
    "                wordsfreq[word]=0\n",
    "            for bigram in lis:\n",
    "                if bigram in word:\n",
    "                    wordsfreq[word]=wordsfreq[word]+1\n",
    "        wordscon=sorted(wordsfreq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        print(\"\\nlet's consider top 20 words:\\n\\n\",wordscon[:20])\n",
    "        for w in range(len(wordscon[:20])):\n",
    "            if wordscon[:20][w][0]==ogword[i]:\n",
    "                mrr+=Decimal(1/(w+1))\n",
    "        if i==len(n)-1:\n",
    "            mrr/=(i+1)\n",
    "            mrr= round(mrr,2)\n",
    "    print('\\nmrr is: ',mrr)\n",
    "    \n",
    "# wor contains mis-spelt words\n",
    "# ogword contains correct spellings of the respective words in wor\n",
    "# n is the n in n-gram\n",
    "\n",
    "spell(['sadenkahdenkimenensietsemn','vardadieramante','balsemered'],['sadankahdenkymmenenseitsemän','verdadeiramente','balsamerad'],[2,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the given word's 2-grams are:  ['$s', 'sa', 'ad', 'de', 'en', 'nk', 'ka', 'ah', 'hd', 'de', 'en', 'nk', 'ki', 'im', 'me', 'en', 'ne', 'en', 'ns', 'si', 'ie', 'et', 'ts', 'se', 'em', 'mn', 'n#'] \n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('$sadankahdenkymmenenseitsemän#', 21), ('$kahden#', 20), ('$ensimmäisen#', 18), ('$sendet#', 18), ('$senhor#', 18), ('$kuitenkin#', 16), ('$vedenpaisumuksen#', 16), ('$syvyyden#', 16), ('$ensimmäisenä#', 16), ('$henkivartijain#', 16), ('$sadanneljänkymmenenseitsemän#', 16), ('$seulement#', 16), ('$seinen#', 16), ('$deinen#', 16), ('$sieben#', 16), ('$fremden#', 16), ('$sprenkligen#', 16), ('$sannerligen#', 16), ('$skynden#', 16), ('$seitsemänkymmenenviiden#', 15)]\n",
      "\n",
      "the given word's 2-grams are:  ['$v', 'va', 'ar', 'rd', 'da', 'ad', 'di', 'ie', 'er', 'ra', 'am', 'ma', 'an', 'nt', 'te', 'e#'] \n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('$quarante#', 12), ('$peradventure#', 10), ('$madianites#', 10), ('$certamente#', 10), ('$vieram#', 10), ('$verdadeiramente#', 10), ('$servant#', 8), ('$afterward#', 8), ('$afterwards#', 8), ('$vaadin#', 8), ('$vieraat#', 8), ('$herramme#', 8), ('$maintenant#', 8), ('$maudite#', 8), ('$enterre#', 8), ('$daran#', 8), ('$vergie#', 8), ('$mantel#', 8), ('$oriente#', 8), ('$disseram#', 8)]\n",
      "\n",
      "the given word's 2-grams are:  ['$b', 'ba', 'al', 'ls', 'se', 'em', 'me', 'er', 're', 'ed', 'd#'] \n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('$blessed#', 8), ('$balsam#', 8), ('$where#', 6), ('$cursed#', 6), ('$remembered#', 6), ('$beersheba#', 6), ('$embalmed#', 6), ('$premier#', 6), ('$certainement#', 6), ('$seulement#', 6), ('$demeure#', 6), ('$abermals#', 6), ('$med#', 6), ('$herre#', 6), ('$balsamera#', 6), ('$balsamerade#', 6), ('$balsamering#', 6), ('$bered#', 5), ('$seemed#', 5), ('$reserved#', 5)]\n",
      "\n",
      "mrr is:  0.39\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import genesis,names,webtext,brown\n",
    "from random import shuffle,sample\n",
    "from decimal import Decimal\n",
    "import operator\n",
    "#nltk.download('webtext')\n",
    "wt = genesis.words()\n",
    "data = nltk.FreqDist((wt))\n",
    "corpus=['$'+m.lower()+'#' for m, n in data.items()]\n",
    "#corpus=sample(corpus,len(corpus))\n",
    "#wor=['$'+wor.lower()+'#' for wor in input(\"\\nenter some mis-spelt words: \").split(',')]\n",
    "#ogword=['$'+ogword.lower()+'#' for ogword in input(\"\\nwhat do you think the og words are: \").split(',')]\n",
    "#n=[int(n)for n in input(\"\\nenter what kind of gramming scheme (integer) : \").split(',')]\n",
    "def spell(wor,ogword,n):\n",
    "    mrr=0\n",
    "    for i in range(len(n)):\n",
    "        lis=[]\n",
    "        z=wor[i]\n",
    "        while len(z)>n[i]-1:\n",
    "            lis.append(z[:n[i]])\n",
    "            z=z[1:]\n",
    "        print(\"\\nthe given word's {}-grams are: \".format(n[i]),lis,'\\n')\n",
    "        wordsfreq={}\n",
    "        for word in corpus:\n",
    "            if word not in wordsfreq:\n",
    "                wordsfreq[word]=0\n",
    "            for bigram in lis:\n",
    "                if bigram in word:\n",
    "                    wordsfreq[word]=wordsfreq[word]+1\n",
    "        wordscon=sorted(wordsfreq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        print(\"let's consider top 20 words:\\n\\n\",wordscon[:20])\n",
    "        for w in range(len(wordscon[:20])):\n",
    "            if wordscon[:20][w][0]==ogword[i]:\n",
    "                mrr+=Decimal(1/(w+1))\n",
    "        if i==len(n)-1:\n",
    "            mrr/=(i+1)\n",
    "            mrr= round(mrr,2)\n",
    "    print('\\nmrr is: ',mrr)\n",
    "    \n",
    "# wor contains mis-spelt words\n",
    "# ogword contains correct spellings of the respective words in wor\n",
    "# n is the n in n-gram\n",
    "    \n",
    "spell(['$sadenkahdenkimenensietsemn#','$vardadieramante#','$balsemered#'],['$sadankahdenkymmenenseitsemän#','$verdadeiramente#','$balsamerad#'],[2,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's randomize the word order in corpus and perform the above two tasks again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the given word's 2-grams are:  ['sa', 'ad', 'de', 'en', 'nk', 'ka', 'ah', 'hd', 'de', 'en', 'nk', 'ki', 'im', 'me', 'en', 'ne', 'en', 'ns', 'si', 'ie', 'et', 'ts', 'se', 'em', 'mn']\n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('sadankahdenkymmenenseitsemän', 19), ('kahden', 18), ('sendet', 16), ('ensimmäisen', 16), ('ensimmäisenä', 16), ('senhor', 15), ('kahdeksankymmentäkuusivuotias', 14), ('menkää', 14), ('fördenskull', 14), ('sadanneljänkymmenenseitsemän', 14), ('denne', 14), ('fremden', 14), ('henkivartijain', 14), ('certainement', 14), ('kaksikymmentä', 14), ('vedenpaisumuksen', 14), ('kuitenkin', 14), ('seulement', 14), ('deinen', 14), ('denied', 14)]\n",
      "\n",
      "the given word's 2-grams are:  ['va', 'ar', 'rd', 'da', 'ad', 'di', 'ie', 'er', 'ra', 'am', 'ma', 'an', 'nt', 'te']\n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('quarante', 10), ('madianites', 10), ('disseram', 8), ('cavaram', 8), ('servant', 8), ('vieram', 8), ('levantei', 8), ('maintenant', 8), ('certamente', 8), ('afterward', 8), ('peradventure', 8), ('afterwards', 8), ('daran', 8), ('mantel', 8), ('mataram', 8), ('verdadeiramente', 8), ('grandissimamente', 7), ('avant', 6), ('mangeraient', 6), ('antes', 6)]\n",
      "\n",
      "the given word's 2-grams are:  ['ba', 'al', 'ls', 'se', 'em', 'me', 'er', 're', 'ed']\n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('herre', 6), ('where', 6), ('certainement', 6), ('premier', 6), ('abermals', 6), ('balsam', 6), ('demeure', 6), ('seulement', 6), ('balsamerade', 5), ('embalsamassem', 5), ('balsamering', 5), ('embalmed', 5), ('balsamera', 5), ('remembered', 5), ('semeber', 4), ('isällemme', 4), ('reise', 4), ('dieser', 4), ('femmes', 4), ('serve', 4)]\n",
      "\n",
      "mrr is:  0.35\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import genesis,names,brown,webtext\n",
    "import operator\n",
    "from random import shuffle,sample\n",
    "from decimal import Decimal\n",
    "#nltk.download('webtext')\n",
    "wt = genesis.words()\n",
    "data = nltk.FreqDist(sorted(wt))\n",
    "corpus=[m.lower() for m, n in data.items()]\n",
    "corpus=sample(corpus,len(corpus))\n",
    "#wor=[wor.lower() for wor in input(\"\\nenter some mis-spelt words: \").split(',')]\n",
    "#ogword=[ogword.lower() for ogword in input(\"\\nwhat do you think the og words are: \").split(',')]\n",
    "#n=[int(n)for n in input(\"\\nenter what kind of gramming scheme (integer) : \").split(',')]\n",
    "def spell(wor,ogword,n):\n",
    "    mrr=0\n",
    "    for i in range(len(n)):\n",
    "        lis=[]\n",
    "        while len(wor[i])>n[i]-1:\n",
    "            lis.append(wor[i][:n[i]])\n",
    "            wor[i]=wor[i][1:]\n",
    "        print(\"\\nthe given word's {}-grams are: \".format(n[i]),lis)\n",
    "        wordsfreq={}\n",
    "        for word in corpus:\n",
    "            if word not in wordsfreq:\n",
    "                wordsfreq[word]=0\n",
    "            for bigram in lis:\n",
    "                if bigram in word:\n",
    "                    wordsfreq[word]=wordsfreq[word]+1\n",
    "        wordscon=sorted(wordsfreq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        print(\"\\nlet's consider top 20 words:\\n\\n\",wordscon[:20])\n",
    "        for w in range(len(wordscon[:20])):\n",
    "            if wordscon[:20][w][0]==ogword[i]:\n",
    "                mrr+=Decimal(1/(w+1))\n",
    "        if i==len(n)-1:\n",
    "            mrr/=(i+1)\n",
    "            mrr= round(mrr,2)\n",
    "    print('\\nmrr is: ',mrr)\n",
    "    \n",
    "# wor contains mis-spelt words\n",
    "# ogword contains correct spellings of the respective words in wor\n",
    "# n is the n in n-gram\n",
    "\n",
    "spell(['sadenkahdenkimenensietsemn','vardadieramante','balsemered'],['sadankahdenkymmenenseitsemän','verdadeiramente','balsamerad'],[2,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the given word's 2-grams are:  ['$s', 'sa', 'ad', 'de', 'en', 'nk', 'ka', 'ah', 'hd', 'de', 'en', 'nk', 'ki', 'im', 'me', 'en', 'ne', 'en', 'ns', 'si', 'ie', 'et', 'ts', 'se', 'em', 'mn', 'n#'] \n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('$sadankahdenkymmenenseitsemän#', 21), ('$kahden#', 20), ('$senhor#', 18), ('$ensimmäisen#', 18), ('$sendet#', 18), ('$sprenkligen#', 16), ('$deinen#', 16), ('$seulement#', 16), ('$vedenpaisumuksen#', 16), ('$sannerligen#', 16), ('$fremden#', 16), ('$skynden#', 16), ('$kuitenkin#', 16), ('$seinen#', 16), ('$ensimmäisenä#', 16), ('$syvyyden#', 16), ('$sadanneljänkymmenenseitsemän#', 16), ('$henkivartijain#', 16), ('$sieben#', 16), ('$seitsemänkymmenenviiden#', 15)]\n",
      "\n",
      "the given word's 2-grams are:  ['$v', 'va', 'ar', 'rd', 'da', 'ad', 'di', 'ie', 'er', 'ra', 'am', 'ma', 'an', 'nt', 'te', 'e#'] \n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('$quarante#', 12), ('$peradventure#', 10), ('$verdadeiramente#', 10), ('$certamente#', 10), ('$vieram#', 10), ('$madianites#', 10), ('$maudite#', 8), ('$oriente#', 8), ('$afterwards#', 8), ('$vandra#', 8), ('$levantei#', 8), ('$servant#', 8), ('$vieraat#', 8), ('$mantel#', 8), ('$ytterligare#', 8), ('$mataram#', 8), ('$daran#', 8), ('$disseram#', 8), ('$vaadin#', 8), ('$enterre#', 8)]\n",
      "\n",
      "the given word's 2-grams are:  ['$b', 'ba', 'al', 'ls', 'se', 'em', 'me', 'er', 're', 'ed', 'd#'] \n",
      "\n",
      "let's consider top 20 words:\n",
      "\n",
      " [('$blessed#', 8), ('$balsam#', 8), ('$abermals#', 6), ('$certainement#', 6), ('$seulement#', 6), ('$herre#', 6), ('$balsamerade#', 6), ('$med#', 6), ('$demeure#', 6), ('$where#', 6), ('$balsamering#', 6), ('$beersheba#', 6), ('$balsamera#', 6), ('$premier#', 6), ('$cursed#', 6), ('$embalmed#', 6), ('$remembered#', 6), ('$bereaved#', 5), ('$bared#', 5), ('$preserved#', 5)]\n",
      "\n",
      "mrr is:  0.44\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import genesis,names,webtext,brown\n",
    "from random import shuffle,sample\n",
    "from decimal import Decimal\n",
    "import operator\n",
    "#nltk.download('webtext')\n",
    "wt = genesis.words()\n",
    "data = nltk.FreqDist((wt))\n",
    "corpus=['$'+m.lower()+'#' for m, n in data.items()]\n",
    "corpus=sample(corpus,len(corpus))\n",
    "#wor=['$'+wor.lower()+'#' for wor in input(\"\\nenter some mis-spelt words: \").split(',')]\n",
    "#ogword=['$'+ogword.lower()+'#' for ogword in input(\"\\nwhat do you think the og words are: \").split(',')]\n",
    "#n=[int(n)for n in input(\"\\nenter what kind of gramming scheme (integer) : \").split(',')]\n",
    "def spell(wor,ogword,n):\n",
    "    mrr=0\n",
    "    for i in range(len(n)):\n",
    "        lis=[]\n",
    "        z=wor[i]\n",
    "        while len(z)>n[i]-1:\n",
    "            lis.append(z[:n[i]])\n",
    "            z=z[1:]\n",
    "        print(\"\\nthe given word's {}-grams are: \".format(n[i]),lis,'\\n')\n",
    "        wordsfreq={}\n",
    "        for word in corpus:\n",
    "            if word not in wordsfreq:\n",
    "                wordsfreq[word]=0\n",
    "            for bigram in lis:\n",
    "                if bigram in word:\n",
    "                    wordsfreq[word]=wordsfreq[word]+1\n",
    "        wordscon=sorted(wordsfreq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        print(\"let's consider top 20 words:\\n\\n\",wordscon[:20])\n",
    "        for w in range(len(wordscon[:20])):\n",
    "            if wordscon[:20][w][0]==ogword[i]:\n",
    "                mrr+=Decimal(1/(w+1))\n",
    "        if i==len(n)-1:\n",
    "            mrr/=(i+1)\n",
    "            mrr= round(mrr,2)\n",
    "    print('\\nmrr is: ',mrr)\n",
    "\n",
    "# wor contains mis-spelt words\n",
    "# ogword contains correct spellings of the respective words in wor\n",
    "# n is the n in n-gram\n",
    "    \n",
    "spell(['$sadenkahdenkimenensietsemn#','$vardadieramante#','$balsemered#'],['$sadankahdenkymmenenseitsemän#','$verdadeiramente#','$balsamerad#'],[2,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I considered genesis corpus and here's the link - http://www.nltk.org/nltk_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the accuracy for the code WITH TAGS is more than the code WITHOUT TAGS. This is because the tags play an important role in matching. Let's say there is a word 'etiquette' and because of those two extra grams, we get more possibilities. But there's always a catch, this could do harm to the accuracy too. What if, beacuse of those extra grams, we get unnecessary hits which are present before the actual one in the final output list? then the rank would be more and the program compromises. But moslty it (with tags) is accurate.\n",
    "And I also doubt whether the order of hits in the output list is legit or not as I have a feeling that it variates along with the ordering of the words in the corpus. So I randomized the word order in the corpus and performed the above two tasks again. Now we can still see the same case, WITH OUT TAGS accuracy < WITH TAGS accuracy. But there are down sides for this code WITH TAGS too. Sometimes we also get same accuracy for both for example if the mis-spelt word is 'educasion' and the the correct counter part is 'education' then the both models would give us the same accuracy as there is highest frequency associated with 'education' words in both models. This is because both models would give very good accuracy when the mis-spelt is varied by just one letter or so."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('py3env': conda)",
   "language": "python",
   "name": "python38364bitpy3envconda25a139e352604301bf121b0d1007e643"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
